{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "import pandas\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier,plot_tree\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import tensorflow as tf\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 2), dtype=float32, numpy=array([[[0.5, 0.5]]], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is a logistic regression in Keras\n",
    "x = tf.keras.Input(shape=(1,8))\n",
    "y = tf.keras.layers.Dense(1024, activation='exponential')(x)\n",
    "y = tf.keras.layers.Dense(1024,activation='relu')(x)\n",
    "y = tf.keras.layers.Dense(1024,activation='relu')(x)\n",
    "y = tf.keras.layers.Dense(1024,activation='relu')(x)\n",
    "# y = tf.keras.layers.Dense(256, activation='exponential')(x)\n",
    "# y = tf.keras.layers.Dense(256, activation='exponential')(x)\n",
    "# y = tf.keras.layers.Dense(32, activation='softmax')(x)\n",
    "# y = tf.keras.layers.Dense(256, activation='exponential')(x)\n",
    "# y = tf.keras.layers.Dense(32, activation='tanh')(x)\n",
    "y = tf.keras.layers.Dense(2, activation='sigmoid')(x)\n",
    "# y = tf.math.argmax(y)\n",
    "model = tf.keras.Model(x, y)\n",
    "model(tf.reshape(np.zeros((1,8)),(1,1,8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>coin</th>\n",
       "      <th>time</th>\n",
       "      <th>all</th>\n",
       "      <th>avgall</th>\n",
       "      <th>avg15</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>price</th>\n",
       "      <th>profit</th>\n",
       "      <th>loss</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>ALPINEUSDT</td>\n",
       "      <td>Sat Apr 23 13:30:59 2022</td>\n",
       "      <td>0.852468</td>\n",
       "      <td>0.893803</td>\n",
       "      <td>0.935138</td>\n",
       "      <td>0.818175</td>\n",
       "      <td>1.018074</td>\n",
       "      <td>1.016046</td>\n",
       "      <td>0.937181</td>\n",
       "      <td>0.886212</td>\n",
       "      <td>6.043900</td>\n",
       "      <td>6.346095</td>\n",
       "      <td>5.741705</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>IDEXUSDT</td>\n",
       "      <td>Sat Apr 23 16:15:32 2022</td>\n",
       "      <td>0.920986</td>\n",
       "      <td>0.896055</td>\n",
       "      <td>0.871123</td>\n",
       "      <td>0.626352</td>\n",
       "      <td>0.967949</td>\n",
       "      <td>0.920218</td>\n",
       "      <td>0.917548</td>\n",
       "      <td>0.923547</td>\n",
       "      <td>0.146715</td>\n",
       "      <td>0.154051</td>\n",
       "      <td>0.139379</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>FXSUSDT</td>\n",
       "      <td>Sat Apr 23 14:29:16 2022</td>\n",
       "      <td>1.797902</td>\n",
       "      <td>1.689345</td>\n",
       "      <td>1.580788</td>\n",
       "      <td>1.330386</td>\n",
       "      <td>1.674091</td>\n",
       "      <td>1.653567</td>\n",
       "      <td>1.632409</td>\n",
       "      <td>1.613489</td>\n",
       "      <td>29.663500</td>\n",
       "      <td>31.146675</td>\n",
       "      <td>28.180325</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>IMXUSDT</td>\n",
       "      <td>Sat Apr 23 13:55:38 2022</td>\n",
       "      <td>1.748623</td>\n",
       "      <td>1.666303</td>\n",
       "      <td>1.583982</td>\n",
       "      <td>1.591580</td>\n",
       "      <td>1.635829</td>\n",
       "      <td>1.588983</td>\n",
       "      <td>1.551715</td>\n",
       "      <td>1.551805</td>\n",
       "      <td>1.850500</td>\n",
       "      <td>1.943025</td>\n",
       "      <td>1.757975</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>SYSUSDT</td>\n",
       "      <td>Sat Apr 23 15:58:53 2022</td>\n",
       "      <td>1.297904</td>\n",
       "      <td>1.274637</td>\n",
       "      <td>1.251370</td>\n",
       "      <td>0.985947</td>\n",
       "      <td>1.119792</td>\n",
       "      <td>1.424015</td>\n",
       "      <td>1.349666</td>\n",
       "      <td>1.377432</td>\n",
       "      <td>0.491900</td>\n",
       "      <td>0.516495</td>\n",
       "      <td>0.467305</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>STEEMUSDT</td>\n",
       "      <td>Sat Apr 23 13:06:36 2022</td>\n",
       "      <td>0.385475</td>\n",
       "      <td>1.134099</td>\n",
       "      <td>1.882723</td>\n",
       "      <td>2.428976</td>\n",
       "      <td>2.019140</td>\n",
       "      <td>1.772344</td>\n",
       "      <td>1.632042</td>\n",
       "      <td>1.561114</td>\n",
       "      <td>0.467550</td>\n",
       "      <td>0.490928</td>\n",
       "      <td>0.444173</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>BICOUSDT</td>\n",
       "      <td>Sat Apr 23 14:29:17 2022</td>\n",
       "      <td>0.651945</td>\n",
       "      <td>0.862594</td>\n",
       "      <td>1.073242</td>\n",
       "      <td>0.968528</td>\n",
       "      <td>1.074435</td>\n",
       "      <td>1.098376</td>\n",
       "      <td>1.103650</td>\n",
       "      <td>1.121219</td>\n",
       "      <td>1.315000</td>\n",
       "      <td>1.380750</td>\n",
       "      <td>1.249250</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>CLVUSDT</td>\n",
       "      <td>Sat Apr 23 17:13:43 2022</td>\n",
       "      <td>0.105800</td>\n",
       "      <td>0.385138</td>\n",
       "      <td>0.664475</td>\n",
       "      <td>0.530575</td>\n",
       "      <td>0.700113</td>\n",
       "      <td>0.690409</td>\n",
       "      <td>0.695351</td>\n",
       "      <td>0.705929</td>\n",
       "      <td>0.330500</td>\n",
       "      <td>0.347025</td>\n",
       "      <td>0.313975</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>AMPUSDT</td>\n",
       "      <td>Sat Apr 23 14:53:52 2022</td>\n",
       "      <td>0.613258</td>\n",
       "      <td>0.882100</td>\n",
       "      <td>1.150942</td>\n",
       "      <td>1.012856</td>\n",
       "      <td>1.195820</td>\n",
       "      <td>1.173454</td>\n",
       "      <td>1.189838</td>\n",
       "      <td>1.182743</td>\n",
       "      <td>0.022310</td>\n",
       "      <td>0.023425</td>\n",
       "      <td>0.021194</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>MLNUSDT</td>\n",
       "      <td>Sat Apr 23 17:22:28 2022</td>\n",
       "      <td>0.119455</td>\n",
       "      <td>0.675173</td>\n",
       "      <td>1.230890</td>\n",
       "      <td>1.331910</td>\n",
       "      <td>1.462860</td>\n",
       "      <td>1.193109</td>\n",
       "      <td>1.091895</td>\n",
       "      <td>1.074676</td>\n",
       "      <td>56.450000</td>\n",
       "      <td>59.272500</td>\n",
       "      <td>53.627500</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>PEOPLEUSDT</td>\n",
       "      <td>Sat Apr 23 14:11:50 2022</td>\n",
       "      <td>0.246142</td>\n",
       "      <td>0.698946</td>\n",
       "      <td>1.151750</td>\n",
       "      <td>1.168421</td>\n",
       "      <td>1.164534</td>\n",
       "      <td>1.144233</td>\n",
       "      <td>1.143566</td>\n",
       "      <td>1.137995</td>\n",
       "      <td>0.049450</td>\n",
       "      <td>0.051923</td>\n",
       "      <td>0.046977</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>ANCUSDT</td>\n",
       "      <td>Sat Apr 23 13:39:24 2022</td>\n",
       "      <td>0.653619</td>\n",
       "      <td>0.911656</td>\n",
       "      <td>1.169693</td>\n",
       "      <td>1.158935</td>\n",
       "      <td>1.160090</td>\n",
       "      <td>1.158780</td>\n",
       "      <td>1.185524</td>\n",
       "      <td>1.185137</td>\n",
       "      <td>1.963500</td>\n",
       "      <td>2.061675</td>\n",
       "      <td>1.865325</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>XECUSDT</td>\n",
       "      <td>Sat Apr 23 16:32:00 2022</td>\n",
       "      <td>0.734169</td>\n",
       "      <td>0.915516</td>\n",
       "      <td>1.096864</td>\n",
       "      <td>0.968636</td>\n",
       "      <td>1.123122</td>\n",
       "      <td>1.120656</td>\n",
       "      <td>1.138977</td>\n",
       "      <td>1.132929</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>TKOUSDT</td>\n",
       "      <td>Sat Apr 23 18:45:02 2022</td>\n",
       "      <td>0.350512</td>\n",
       "      <td>1.451437</td>\n",
       "      <td>2.552362</td>\n",
       "      <td>2.817598</td>\n",
       "      <td>2.946662</td>\n",
       "      <td>2.589133</td>\n",
       "      <td>2.246651</td>\n",
       "      <td>2.161765</td>\n",
       "      <td>0.709500</td>\n",
       "      <td>0.744975</td>\n",
       "      <td>0.674025</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>FLOWUSDT</td>\n",
       "      <td>Sat Apr 23 17:05:33 2022</td>\n",
       "      <td>0.380030</td>\n",
       "      <td>0.807794</td>\n",
       "      <td>1.235558</td>\n",
       "      <td>1.226093</td>\n",
       "      <td>1.240074</td>\n",
       "      <td>1.237796</td>\n",
       "      <td>1.233859</td>\n",
       "      <td>1.239968</td>\n",
       "      <td>5.625000</td>\n",
       "      <td>5.906250</td>\n",
       "      <td>5.343750</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>VOXELUSDT</td>\n",
       "      <td>Sat Apr 23 14:21:16 2022</td>\n",
       "      <td>1.194703</td>\n",
       "      <td>1.073472</td>\n",
       "      <td>0.952241</td>\n",
       "      <td>1.087364</td>\n",
       "      <td>1.012340</td>\n",
       "      <td>0.892390</td>\n",
       "      <td>0.885907</td>\n",
       "      <td>0.883202</td>\n",
       "      <td>1.371700</td>\n",
       "      <td>1.440285</td>\n",
       "      <td>1.303115</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>121</td>\n",
       "      <td>121</td>\n",
       "      <td>BADGERUSDT</td>\n",
       "      <td>Sat Apr 23 19:16:49 2022</td>\n",
       "      <td>0.449408</td>\n",
       "      <td>1.178334</td>\n",
       "      <td>1.907260</td>\n",
       "      <td>2.218949</td>\n",
       "      <td>1.954366</td>\n",
       "      <td>1.822803</td>\n",
       "      <td>1.777040</td>\n",
       "      <td>1.763139</td>\n",
       "      <td>8.770000</td>\n",
       "      <td>9.208500</td>\n",
       "      <td>8.331500</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>POLYUSDT</td>\n",
       "      <td>Sat Apr 23 16:24:01 2022</td>\n",
       "      <td>0.634725</td>\n",
       "      <td>1.254896</td>\n",
       "      <td>1.875068</td>\n",
       "      <td>1.815818</td>\n",
       "      <td>1.958532</td>\n",
       "      <td>1.897289</td>\n",
       "      <td>1.858774</td>\n",
       "      <td>1.844927</td>\n",
       "      <td>0.439550</td>\n",
       "      <td>0.461527</td>\n",
       "      <td>0.417572</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>LITUSDT</td>\n",
       "      <td>Sat Apr 23 19:33:10 2022</td>\n",
       "      <td>0.366939</td>\n",
       "      <td>1.193365</td>\n",
       "      <td>2.019792</td>\n",
       "      <td>2.254900</td>\n",
       "      <td>2.158164</td>\n",
       "      <td>1.905427</td>\n",
       "      <td>1.891628</td>\n",
       "      <td>1.888839</td>\n",
       "      <td>1.367500</td>\n",
       "      <td>1.435875</td>\n",
       "      <td>1.299125</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>VIDTUSDT</td>\n",
       "      <td>Sat Apr 23 16:15:01 2022</td>\n",
       "      <td>0.323830</td>\n",
       "      <td>0.463583</td>\n",
       "      <td>0.603335</td>\n",
       "      <td>0.618913</td>\n",
       "      <td>0.613345</td>\n",
       "      <td>0.573984</td>\n",
       "      <td>0.604975</td>\n",
       "      <td>0.605459</td>\n",
       "      <td>0.430250</td>\n",
       "      <td>0.451763</td>\n",
       "      <td>0.408737</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>PHAUSDT</td>\n",
       "      <td>Sat Apr 23 17:30:32 2022</td>\n",
       "      <td>0.694276</td>\n",
       "      <td>3.870480</td>\n",
       "      <td>7.046684</td>\n",
       "      <td>9.624844</td>\n",
       "      <td>7.853325</td>\n",
       "      <td>6.348099</td>\n",
       "      <td>5.787873</td>\n",
       "      <td>5.619282</td>\n",
       "      <td>0.275300</td>\n",
       "      <td>0.289065</td>\n",
       "      <td>0.261535</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>TORNUSDT</td>\n",
       "      <td>Sat Apr 23 17:38:59 2022</td>\n",
       "      <td>0.927490</td>\n",
       "      <td>1.643140</td>\n",
       "      <td>2.358791</td>\n",
       "      <td>3.553325</td>\n",
       "      <td>2.500901</td>\n",
       "      <td>1.990190</td>\n",
       "      <td>1.897370</td>\n",
       "      <td>1.852167</td>\n",
       "      <td>46.570000</td>\n",
       "      <td>48.898500</td>\n",
       "      <td>44.241500</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>BURGERUSDT</td>\n",
       "      <td>Sat Apr 23 18:20:36 2022</td>\n",
       "      <td>0.192450</td>\n",
       "      <td>0.777440</td>\n",
       "      <td>1.362430</td>\n",
       "      <td>1.737629</td>\n",
       "      <td>1.699390</td>\n",
       "      <td>1.228503</td>\n",
       "      <td>1.102486</td>\n",
       "      <td>1.044144</td>\n",
       "      <td>1.392000</td>\n",
       "      <td>1.461600</td>\n",
       "      <td>1.322400</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>ALICEUSDT</td>\n",
       "      <td>Sat Apr 23 19:09:02 2022</td>\n",
       "      <td>0.499505</td>\n",
       "      <td>0.763653</td>\n",
       "      <td>1.027801</td>\n",
       "      <td>1.053512</td>\n",
       "      <td>1.012612</td>\n",
       "      <td>1.023240</td>\n",
       "      <td>1.023024</td>\n",
       "      <td>1.026619</td>\n",
       "      <td>6.485000</td>\n",
       "      <td>6.809250</td>\n",
       "      <td>6.160750</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>ENSUSDT</td>\n",
       "      <td>Sat Apr 23 15:10:04 2022</td>\n",
       "      <td>1.275914</td>\n",
       "      <td>1.298223</td>\n",
       "      <td>1.320532</td>\n",
       "      <td>1.320326</td>\n",
       "      <td>1.377078</td>\n",
       "      <td>1.315689</td>\n",
       "      <td>1.295055</td>\n",
       "      <td>1.294511</td>\n",
       "      <td>13.915000</td>\n",
       "      <td>14.610750</td>\n",
       "      <td>13.219250</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "      <td>PUNDIXUSDT</td>\n",
       "      <td>Sat Apr 23 18:44:53 2022</td>\n",
       "      <td>0.230102</td>\n",
       "      <td>0.946749</td>\n",
       "      <td>1.663397</td>\n",
       "      <td>1.808102</td>\n",
       "      <td>1.605972</td>\n",
       "      <td>1.631549</td>\n",
       "      <td>1.635046</td>\n",
       "      <td>1.636316</td>\n",
       "      <td>0.853500</td>\n",
       "      <td>0.896175</td>\n",
       "      <td>0.810825</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>CAKEUSDT</td>\n",
       "      <td>Sat Apr 23 19:24:46 2022</td>\n",
       "      <td>0.693320</td>\n",
       "      <td>0.703542</td>\n",
       "      <td>0.713763</td>\n",
       "      <td>0.730575</td>\n",
       "      <td>0.667795</td>\n",
       "      <td>0.713102</td>\n",
       "      <td>0.714875</td>\n",
       "      <td>0.742468</td>\n",
       "      <td>9.415000</td>\n",
       "      <td>9.885750</td>\n",
       "      <td>8.944250</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>TRUUSDT</td>\n",
       "      <td>Sat Apr 23 19:41:19 2022</td>\n",
       "      <td>0.603583</td>\n",
       "      <td>0.954883</td>\n",
       "      <td>1.306183</td>\n",
       "      <td>1.314222</td>\n",
       "      <td>1.419225</td>\n",
       "      <td>1.344590</td>\n",
       "      <td>1.230845</td>\n",
       "      <td>1.222031</td>\n",
       "      <td>0.193500</td>\n",
       "      <td>0.203175</td>\n",
       "      <td>0.183825</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>RAREUSDT</td>\n",
       "      <td>Sat Apr 23 15:42:46 2022</td>\n",
       "      <td>0.144411</td>\n",
       "      <td>0.480619</td>\n",
       "      <td>0.816827</td>\n",
       "      <td>0.837178</td>\n",
       "      <td>0.878592</td>\n",
       "      <td>0.772470</td>\n",
       "      <td>0.773239</td>\n",
       "      <td>0.822654</td>\n",
       "      <td>0.576500</td>\n",
       "      <td>0.605325</td>\n",
       "      <td>0.547675</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>ADXUSDT</td>\n",
       "      <td>Sat Apr 23 15:34:16 2022</td>\n",
       "      <td>3.121998</td>\n",
       "      <td>2.242322</td>\n",
       "      <td>1.362646</td>\n",
       "      <td>1.800168</td>\n",
       "      <td>1.345370</td>\n",
       "      <td>1.214556</td>\n",
       "      <td>1.224872</td>\n",
       "      <td>1.228264</td>\n",
       "      <td>0.373600</td>\n",
       "      <td>0.392280</td>\n",
       "      <td>0.354920</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>SFPUSDT</td>\n",
       "      <td>Sat Apr 23 19:33:34 2022</td>\n",
       "      <td>0.689913</td>\n",
       "      <td>0.956331</td>\n",
       "      <td>1.222750</td>\n",
       "      <td>1.240350</td>\n",
       "      <td>1.369228</td>\n",
       "      <td>1.234228</td>\n",
       "      <td>1.129232</td>\n",
       "      <td>1.140712</td>\n",
       "      <td>0.795550</td>\n",
       "      <td>0.835328</td>\n",
       "      <td>0.755772</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>114</td>\n",
       "      <td>114</td>\n",
       "      <td>RAMPUSDT</td>\n",
       "      <td>Sat Apr 23 19:01:00 2022</td>\n",
       "      <td>0.279211</td>\n",
       "      <td>0.556771</td>\n",
       "      <td>0.834330</td>\n",
       "      <td>0.826127</td>\n",
       "      <td>0.888803</td>\n",
       "      <td>0.817492</td>\n",
       "      <td>0.815425</td>\n",
       "      <td>0.823803</td>\n",
       "      <td>0.092350</td>\n",
       "      <td>0.096967</td>\n",
       "      <td>0.087732</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>DEXEUSDT</td>\n",
       "      <td>Sat Apr 23 17:21:50 2022</td>\n",
       "      <td>0.212337</td>\n",
       "      <td>0.428224</td>\n",
       "      <td>0.644112</td>\n",
       "      <td>0.489297</td>\n",
       "      <td>0.619528</td>\n",
       "      <td>0.596075</td>\n",
       "      <td>0.758433</td>\n",
       "      <td>0.757226</td>\n",
       "      <td>6.015000</td>\n",
       "      <td>6.315750</td>\n",
       "      <td>5.714250</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>WOOUSDT</td>\n",
       "      <td>Sat Apr 23 13:31:15 2022</td>\n",
       "      <td>1.400121</td>\n",
       "      <td>1.509170</td>\n",
       "      <td>1.618218</td>\n",
       "      <td>1.599625</td>\n",
       "      <td>1.651856</td>\n",
       "      <td>1.614228</td>\n",
       "      <td>1.616351</td>\n",
       "      <td>1.609033</td>\n",
       "      <td>0.454150</td>\n",
       "      <td>0.476857</td>\n",
       "      <td>0.431442</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>JASMYUSDT</td>\n",
       "      <td>Sat Apr 23 14:53:53 2022</td>\n",
       "      <td>0.188479</td>\n",
       "      <td>0.427231</td>\n",
       "      <td>0.665982</td>\n",
       "      <td>0.640518</td>\n",
       "      <td>0.686754</td>\n",
       "      <td>0.667920</td>\n",
       "      <td>0.664533</td>\n",
       "      <td>0.670186</td>\n",
       "      <td>0.023050</td>\n",
       "      <td>0.024202</td>\n",
       "      <td>0.021898</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>RADUSDT</td>\n",
       "      <td>Sat Apr 23 15:42:18 2022</td>\n",
       "      <td>0.508903</td>\n",
       "      <td>0.803179</td>\n",
       "      <td>1.097455</td>\n",
       "      <td>0.910287</td>\n",
       "      <td>1.118161</td>\n",
       "      <td>1.176795</td>\n",
       "      <td>1.140069</td>\n",
       "      <td>1.141963</td>\n",
       "      <td>4.453000</td>\n",
       "      <td>4.675650</td>\n",
       "      <td>4.230350</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>FRONTUSDT</td>\n",
       "      <td>Sat Apr 23 15:50:38 2022</td>\n",
       "      <td>1.014891</td>\n",
       "      <td>1.765541</td>\n",
       "      <td>2.516192</td>\n",
       "      <td>2.942701</td>\n",
       "      <td>2.764025</td>\n",
       "      <td>2.361296</td>\n",
       "      <td>2.251537</td>\n",
       "      <td>2.261400</td>\n",
       "      <td>0.507100</td>\n",
       "      <td>0.532455</td>\n",
       "      <td>0.481745</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>TUSDT</td>\n",
       "      <td>Sat Apr 23 13:31:08 2022</td>\n",
       "      <td>0.258216</td>\n",
       "      <td>1.191795</td>\n",
       "      <td>2.125375</td>\n",
       "      <td>2.112563</td>\n",
       "      <td>2.168364</td>\n",
       "      <td>2.130255</td>\n",
       "      <td>2.105649</td>\n",
       "      <td>2.110042</td>\n",
       "      <td>0.107100</td>\n",
       "      <td>0.112455</td>\n",
       "      <td>0.101745</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>OMUSDT</td>\n",
       "      <td>Sat Apr 23 19:16:42 2022</td>\n",
       "      <td>0.263117</td>\n",
       "      <td>1.203378</td>\n",
       "      <td>2.143640</td>\n",
       "      <td>2.435829</td>\n",
       "      <td>2.137888</td>\n",
       "      <td>2.058003</td>\n",
       "      <td>2.040414</td>\n",
       "      <td>2.046064</td>\n",
       "      <td>0.096200</td>\n",
       "      <td>0.101010</td>\n",
       "      <td>0.091390</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>DFUSDT</td>\n",
       "      <td>Sat Apr 23 15:59:05 2022</td>\n",
       "      <td>0.080388</td>\n",
       "      <td>1.038312</td>\n",
       "      <td>1.996236</td>\n",
       "      <td>3.080287</td>\n",
       "      <td>2.033892</td>\n",
       "      <td>1.737955</td>\n",
       "      <td>1.593150</td>\n",
       "      <td>1.535898</td>\n",
       "      <td>0.070500</td>\n",
       "      <td>0.074025</td>\n",
       "      <td>0.066975</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>123</td>\n",
       "      <td>123</td>\n",
       "      <td>ACMUSDT</td>\n",
       "      <td>Sat Apr 23 19:24:40 2022</td>\n",
       "      <td>0.397930</td>\n",
       "      <td>0.650461</td>\n",
       "      <td>0.902993</td>\n",
       "      <td>1.411697</td>\n",
       "      <td>1.067274</td>\n",
       "      <td>0.719812</td>\n",
       "      <td>0.676570</td>\n",
       "      <td>0.639614</td>\n",
       "      <td>6.055000</td>\n",
       "      <td>6.357750</td>\n",
       "      <td>5.752250</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>TVKUSDT</td>\n",
       "      <td>Sat Apr 23 17:05:14 2022</td>\n",
       "      <td>0.257898</td>\n",
       "      <td>0.765133</td>\n",
       "      <td>1.272367</td>\n",
       "      <td>1.227299</td>\n",
       "      <td>1.352981</td>\n",
       "      <td>1.235004</td>\n",
       "      <td>1.268866</td>\n",
       "      <td>1.277685</td>\n",
       "      <td>0.103350</td>\n",
       "      <td>0.108518</td>\n",
       "      <td>0.098182</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>ICPUSDT</td>\n",
       "      <td>Sat Apr 23 18:12:30 2022</td>\n",
       "      <td>1.680684</td>\n",
       "      <td>1.420837</td>\n",
       "      <td>1.160990</td>\n",
       "      <td>1.130597</td>\n",
       "      <td>1.157207</td>\n",
       "      <td>1.178951</td>\n",
       "      <td>1.172657</td>\n",
       "      <td>1.165540</td>\n",
       "      <td>16.785000</td>\n",
       "      <td>17.624250</td>\n",
       "      <td>15.945750</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>MIRUSDT</td>\n",
       "      <td>Sat Apr 23 18:28:51 2022</td>\n",
       "      <td>0.636050</td>\n",
       "      <td>0.717782</td>\n",
       "      <td>0.799515</td>\n",
       "      <td>0.726576</td>\n",
       "      <td>0.817654</td>\n",
       "      <td>0.814000</td>\n",
       "      <td>0.818461</td>\n",
       "      <td>0.820882</td>\n",
       "      <td>1.366000</td>\n",
       "      <td>1.434300</td>\n",
       "      <td>1.297700</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  Unnamed: 0.1        coin                      time       all  \\\n",
       "1            6             6  ALPINEUSDT  Sat Apr 23 13:30:59 2022  0.852468   \n",
       "34          60            60    IDEXUSDT  Sat Apr 23 16:15:32 2022  0.920986   \n",
       "3           25            25     FXSUSDT  Sat Apr 23 14:29:16 2022  1.797902   \n",
       "29          15            15     IMXUSDT  Sat Apr 23 13:55:38 2022  1.748623   \n",
       "8           54            54     SYSUSDT  Sat Apr 23 15:58:53 2022  1.297904   \n",
       "0            2             2   STEEMUSDT  Sat Apr 23 13:06:36 2022  0.385475   \n",
       "35          26            26    BICOUSDT  Sat Apr 23 14:29:17 2022  0.651945   \n",
       "22          80            80     CLVUSDT  Sat Apr 23 17:13:43 2022  0.105800   \n",
       "36          33            33     AMPUSDT  Sat Apr 23 14:53:52 2022  0.613258   \n",
       "14          85            85     MLNUSDT  Sat Apr 23 17:22:28 2022  0.119455   \n",
       "37          19            19  PEOPLEUSDT  Sat Apr 23 14:11:50 2022  0.246142   \n",
       "40          10            10     ANCUSDT  Sat Apr 23 13:39:24 2022  0.653619   \n",
       "43          65            65     XECUSDT  Sat Apr 23 16:32:00 2022  0.734169   \n",
       "39         110           110     TKOUSDT  Sat Apr 23 18:45:02 2022  0.350512   \n",
       "25          78            78    FLOWUSDT  Sat Apr 23 17:05:33 2022  0.380030   \n",
       "41          24            24   VOXELUSDT  Sat Apr 23 14:21:16 2022  1.194703   \n",
       "20         121           121  BADGERUSDT  Sat Apr 23 19:16:49 2022  0.449408   \n",
       "11          63            63    POLYUSDT  Sat Apr 23 16:24:01 2022  0.634725   \n",
       "32         126           126     LITUSDT  Sat Apr 23 19:33:10 2022  0.366939   \n",
       "10          59            59    VIDTUSDT  Sat Apr 23 16:15:01 2022  0.323830   \n",
       "15          86            86     PHAUSDT  Sat Apr 23 17:30:32 2022  0.694276   \n",
       "16          90            90    TORNUSDT  Sat Apr 23 17:38:59 2022  0.927490   \n",
       "31         103           103  BURGERUSDT  Sat Apr 23 18:20:36 2022  0.192450   \n",
       "38         118           118   ALICEUSDT  Sat Apr 23 19:09:02 2022  0.499505   \n",
       "5           39            39     ENSUSDT  Sat Apr 23 15:10:04 2022  1.275914   \n",
       "17         109           109  PUNDIXUSDT  Sat Apr 23 18:44:53 2022  0.230102   \n",
       "23         124           124    CAKEUSDT  Sat Apr 23 19:24:46 2022  0.693320   \n",
       "21         130           130     TRUUSDT  Sat Apr 23 19:41:19 2022  0.603583   \n",
       "7           50            50    RAREUSDT  Sat Apr 23 15:42:46 2022  0.144411   \n",
       "30          47            47     ADXUSDT  Sat Apr 23 15:34:16 2022  3.121998   \n",
       "28         128           128     SFPUSDT  Sat Apr 23 19:33:34 2022  0.689913   \n",
       "18         114           114    RAMPUSDT  Sat Apr 23 19:01:00 2022  0.279211   \n",
       "13          84            84    DEXEUSDT  Sat Apr 23 17:21:50 2022  0.212337   \n",
       "33           8             8     WOOUSDT  Sat Apr 23 13:31:15 2022  1.400121   \n",
       "4           34            34   JASMYUSDT  Sat Apr 23 14:53:53 2022  0.188479   \n",
       "6           49            49     RADUSDT  Sat Apr 23 15:42:18 2022  0.508903   \n",
       "24          51            51   FRONTUSDT  Sat Apr 23 15:50:38 2022  1.014891   \n",
       "2            7             7       TUSDT  Sat Apr 23 13:31:08 2022  0.258216   \n",
       "19         120           120      OMUSDT  Sat Apr 23 19:16:42 2022  0.263117   \n",
       "9           55            55      DFUSDT  Sat Apr 23 15:59:05 2022  0.080388   \n",
       "26         123           123     ACMUSDT  Sat Apr 23 19:24:40 2022  0.397930   \n",
       "12          77            77     TVKUSDT  Sat Apr 23 17:05:14 2022  0.257898   \n",
       "27         100           100     ICPUSDT  Sat Apr 23 18:12:30 2022  1.680684   \n",
       "42         106           106     MIRUSDT  Sat Apr 23 18:28:51 2022  0.636050   \n",
       "\n",
       "      avgall     avg15         1         2         3         4         5  \\\n",
       "1   0.893803  0.935138  0.818175  1.018074  1.016046  0.937181  0.886212   \n",
       "34  0.896055  0.871123  0.626352  0.967949  0.920218  0.917548  0.923547   \n",
       "3   1.689345  1.580788  1.330386  1.674091  1.653567  1.632409  1.613489   \n",
       "29  1.666303  1.583982  1.591580  1.635829  1.588983  1.551715  1.551805   \n",
       "8   1.274637  1.251370  0.985947  1.119792  1.424015  1.349666  1.377432   \n",
       "0   1.134099  1.882723  2.428976  2.019140  1.772344  1.632042  1.561114   \n",
       "35  0.862594  1.073242  0.968528  1.074435  1.098376  1.103650  1.121219   \n",
       "22  0.385138  0.664475  0.530575  0.700113  0.690409  0.695351  0.705929   \n",
       "36  0.882100  1.150942  1.012856  1.195820  1.173454  1.189838  1.182743   \n",
       "14  0.675173  1.230890  1.331910  1.462860  1.193109  1.091895  1.074676   \n",
       "37  0.698946  1.151750  1.168421  1.164534  1.144233  1.143566  1.137995   \n",
       "40  0.911656  1.169693  1.158935  1.160090  1.158780  1.185524  1.185137   \n",
       "43  0.915516  1.096864  0.968636  1.123122  1.120656  1.138977  1.132929   \n",
       "39  1.451437  2.552362  2.817598  2.946662  2.589133  2.246651  2.161765   \n",
       "25  0.807794  1.235558  1.226093  1.240074  1.237796  1.233859  1.239968   \n",
       "41  1.073472  0.952241  1.087364  1.012340  0.892390  0.885907  0.883202   \n",
       "20  1.178334  1.907260  2.218949  1.954366  1.822803  1.777040  1.763139   \n",
       "11  1.254896  1.875068  1.815818  1.958532  1.897289  1.858774  1.844927   \n",
       "32  1.193365  2.019792  2.254900  2.158164  1.905427  1.891628  1.888839   \n",
       "10  0.463583  0.603335  0.618913  0.613345  0.573984  0.604975  0.605459   \n",
       "15  3.870480  7.046684  9.624844  7.853325  6.348099  5.787873  5.619282   \n",
       "16  1.643140  2.358791  3.553325  2.500901  1.990190  1.897370  1.852167   \n",
       "31  0.777440  1.362430  1.737629  1.699390  1.228503  1.102486  1.044144   \n",
       "38  0.763653  1.027801  1.053512  1.012612  1.023240  1.023024  1.026619   \n",
       "5   1.298223  1.320532  1.320326  1.377078  1.315689  1.295055  1.294511   \n",
       "17  0.946749  1.663397  1.808102  1.605972  1.631549  1.635046  1.636316   \n",
       "23  0.703542  0.713763  0.730575  0.667795  0.713102  0.714875  0.742468   \n",
       "21  0.954883  1.306183  1.314222  1.419225  1.344590  1.230845  1.222031   \n",
       "7   0.480619  0.816827  0.837178  0.878592  0.772470  0.773239  0.822654   \n",
       "30  2.242322  1.362646  1.800168  1.345370  1.214556  1.224872  1.228264   \n",
       "28  0.956331  1.222750  1.240350  1.369228  1.234228  1.129232  1.140712   \n",
       "18  0.556771  0.834330  0.826127  0.888803  0.817492  0.815425  0.823803   \n",
       "13  0.428224  0.644112  0.489297  0.619528  0.596075  0.758433  0.757226   \n",
       "33  1.509170  1.618218  1.599625  1.651856  1.614228  1.616351  1.609033   \n",
       "4   0.427231  0.665982  0.640518  0.686754  0.667920  0.664533  0.670186   \n",
       "6   0.803179  1.097455  0.910287  1.118161  1.176795  1.140069  1.141963   \n",
       "24  1.765541  2.516192  2.942701  2.764025  2.361296  2.251537  2.261400   \n",
       "2   1.191795  2.125375  2.112563  2.168364  2.130255  2.105649  2.110042   \n",
       "19  1.203378  2.143640  2.435829  2.137888  2.058003  2.040414  2.046064   \n",
       "9   1.038312  1.996236  3.080287  2.033892  1.737955  1.593150  1.535898   \n",
       "26  0.650461  0.902993  1.411697  1.067274  0.719812  0.676570  0.639614   \n",
       "12  0.765133  1.272367  1.227299  1.352981  1.235004  1.268866  1.277685   \n",
       "27  1.420837  1.160990  1.130597  1.157207  1.178951  1.172657  1.165540   \n",
       "42  0.717782  0.799515  0.726576  0.817654  0.814000  0.818461  0.820882   \n",
       "\n",
       "        price     profit       loss answer  \n",
       "1    6.043900   6.346095   5.741705   True  \n",
       "34   0.146715   0.154051   0.139379  False  \n",
       "3   29.663500  31.146675  28.180325   True  \n",
       "29   1.850500   1.943025   1.757975  False  \n",
       "8    0.491900   0.516495   0.467305   True  \n",
       "0    0.467550   0.490928   0.444173   True  \n",
       "35   1.315000   1.380750   1.249250  False  \n",
       "22   0.330500   0.347025   0.313975  False  \n",
       "36   0.022310   0.023425   0.021194  False  \n",
       "14  56.450000  59.272500  53.627500   True  \n",
       "37   0.049450   0.051923   0.046977  False  \n",
       "40   1.963500   2.061675   1.865325  False  \n",
       "43   0.000091   0.000096   0.000087  False  \n",
       "39   0.709500   0.744975   0.674025  False  \n",
       "25   5.625000   5.906250   5.343750  False  \n",
       "41   1.371700   1.440285   1.303115  False  \n",
       "20   8.770000   9.208500   8.331500   True  \n",
       "11   0.439550   0.461527   0.417572   True  \n",
       "32   1.367500   1.435875   1.299125  False  \n",
       "10   0.430250   0.451763   0.408737   True  \n",
       "15   0.275300   0.289065   0.261535   True  \n",
       "16  46.570000  48.898500  44.241500   True  \n",
       "31   1.392000   1.461600   1.322400  False  \n",
       "38   6.485000   6.809250   6.160750  False  \n",
       "5   13.915000  14.610750  13.219250   True  \n",
       "17   0.853500   0.896175   0.810825   True  \n",
       "23   9.415000   9.885750   8.944250  False  \n",
       "21   0.193500   0.203175   0.183825   True  \n",
       "7    0.576500   0.605325   0.547675   True  \n",
       "30   0.373600   0.392280   0.354920  False  \n",
       "28   0.795550   0.835328   0.755772  False  \n",
       "18   0.092350   0.096967   0.087732   True  \n",
       "13   6.015000   6.315750   5.714250   True  \n",
       "33   0.454150   0.476857   0.431442  False  \n",
       "4    0.023050   0.024202   0.021898   True  \n",
       "6    4.453000   4.675650   4.230350   True  \n",
       "24   0.507100   0.532455   0.481745  False  \n",
       "2    0.107100   0.112455   0.101745   True  \n",
       "19   0.096200   0.101010   0.091390   True  \n",
       "9    0.070500   0.074025   0.066975   True  \n",
       "26   6.055000   6.357750   5.752250  False  \n",
       "12   0.103350   0.108518   0.098182   True  \n",
       "27  16.785000  17.624250  15.945750  False  \n",
       "42   1.366000   1.434300   1.297700  False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_csv(\"./data_.csv\")\n",
    "# df.drop(['1','2','3','4','5'],axis=)\n",
    "t = df[df['answer'] == True]\n",
    "# df.loc[ pandas.isnull(df['answer']),'answer'] = False\n",
    "f = df[df['answer'] == False].sample(len(t))\n",
    "print(len(f))\n",
    "df = pandas.concat([t,f],ignore_index=True)\n",
    "df = df.sample(frac=1)\n",
    "df\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf = RandomForestClassifier(n_estimators=2000)\n",
    "\n",
    "# # X_train, X_test, y_train, y_test =  train_test_split(df[['100line','avgall','avg1-5']],df['answer'],shuffle=True,test_size=0.1)\n",
    "\n",
    "\n",
    "# # rf.fit(X =X_train,y=y_train)\n",
    "# rf.fit(X =df[['all','avgall','avg15','1','2','3','4','5']],y=df['answer'])\n",
    "\n",
    "\n",
    "# data = [\n",
    "#     [0.457,1.038,1.619],#\n",
    "# ]\n",
    "\n",
    "\n",
    "# rf.predict(data)\n",
    "\n",
    "\n",
    "\n",
    "# rf.score(X = X_test,y=y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['all','avgall','avg15','answer']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "3/3 [==============================] - 1s 17ms/step - loss: 0.5063 - acc: 0.5000 - recall: 0.2727\n",
      "Epoch 2/300\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5062 - acc: 0.5000 - recall: 0.2727\n",
      "Epoch 3/300\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5063 - acc: 0.5000 - recall: 0.2727\n",
      "Epoch 4/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5061 - acc: 0.5000 - recall: 0.2727\n",
      "Epoch 5/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5061 - acc: 0.5000 - recall: 0.2727\n",
      "Epoch 6/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5061 - acc: 0.5000 - recall: 0.2727\n",
      "Epoch 7/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5061 - acc: 0.5000 - recall: 0.2727\n",
      "Epoch 8/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5061 - acc: 0.5000 - recall: 0.2727\n",
      "Epoch 9/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5060 - acc: 0.5000 - recall: 0.2727\n",
      "Epoch 10/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5060 - acc: 0.5000 - recall: 0.2727\n",
      "Epoch 11/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5060 - acc: 0.5000 - recall: 0.2727\n",
      "Epoch 12/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5059 - acc: 0.5000 - recall: 0.2727\n",
      "Epoch 13/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5059 - acc: 0.5000 - recall: 0.2727\n",
      "Epoch 14/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5059 - acc: 0.5000 - recall: 0.2727\n",
      "Epoch 15/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5058 - acc: 0.5000 - recall: 0.2727\n",
      "Epoch 16/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5058 - acc: 0.5000 - recall: 0.2727\n",
      "Epoch 17/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5058 - acc: 0.5000 - recall: 0.2727\n",
      "Epoch 18/300\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5058 - acc: 0.5000 - recall: 0.2727\n",
      "Epoch 19/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5057 - acc: 0.5000 - recall: 0.2727\n",
      "Epoch 20/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5057 - acc: 0.5000 - recall: 0.2727\n",
      "Epoch 21/300\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5057 - acc: 0.5000 - recall: 0.2727\n",
      "Epoch 22/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5056 - acc: 0.5000 - recall: 0.2727\n",
      "Epoch 23/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5056 - acc: 0.5000 - recall: 0.2727\n",
      "Epoch 24/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5056 - acc: 0.5000 - recall: 0.2727\n",
      "Epoch 25/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5056 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 26/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5055 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 27/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5055 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 28/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5055 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 29/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5055 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 30/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5054 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 31/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5054 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 32/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5054 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 33/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5053 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 34/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5053 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 35/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5053 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 36/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5052 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 37/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5052 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 38/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5052 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 39/300\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5052 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 40/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5051 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 41/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5051 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 42/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5051 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 43/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5051 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 44/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5050 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 45/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5050 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 46/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5050 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 47/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5049 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 48/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5049 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 49/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5049 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 50/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5048 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 51/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5048 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 52/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5048 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 53/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5047 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 54/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5047 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 55/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5047 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 56/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5046 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 57/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5046 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 58/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5046 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 59/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5046 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 60/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5046 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 61/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5045 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 62/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5045 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 63/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5044 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 64/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5044 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 65/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5044 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 66/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5043 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 67/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5043 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 68/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5043 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 69/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5042 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 70/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5042 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 71/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5042 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 72/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5042 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 73/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5041 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 74/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5041 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 75/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5041 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 76/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5041 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 77/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5040 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 78/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5040 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 79/300\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5039 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 80/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5039 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 81/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5039 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 82/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5039 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 83/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5038 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 84/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5038 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 85/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5038 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 86/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5037 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 87/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5037 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 88/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5037 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 89/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5036 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 90/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5036 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 91/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5036 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 92/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5036 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 93/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5036 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 94/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5035 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 95/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5035 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 96/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5034 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 97/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5034 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 98/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5034 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 99/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5034 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 100/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5033 - acc: 0.5000 - recall: 0.3182\n",
      "Epoch 101/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5033 - acc: 0.5000 - recall: 0.3636\n",
      "Epoch 102/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5033 - acc: 0.5000 - recall: 0.3636\n",
      "Epoch 103/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5032 - acc: 0.5000 - recall: 0.3636\n",
      "Epoch 104/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5033 - acc: 0.5000 - recall: 0.3636\n",
      "Epoch 105/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5032 - acc: 0.5000 - recall: 0.3636\n",
      "Epoch 106/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5032 - acc: 0.5000 - recall: 0.3636\n",
      "Epoch 107/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5031 - acc: 0.5000 - recall: 0.3636\n",
      "Epoch 108/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5031 - acc: 0.5000 - recall: 0.3636\n",
      "Epoch 109/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5031 - acc: 0.5000 - recall: 0.3636\n",
      "Epoch 110/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5031 - acc: 0.5000 - recall: 0.3636\n",
      "Epoch 111/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5030 - acc: 0.5000 - recall: 0.3636\n",
      "Epoch 112/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5030 - acc: 0.5000 - recall: 0.3636\n",
      "Epoch 113/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5030 - acc: 0.5000 - recall: 0.3636\n",
      "Epoch 114/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5029 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 115/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5029 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 116/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5029 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 117/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5028 - acc: 0.5000 - recall: 0.3636\n",
      "Epoch 118/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5028 - acc: 0.5000 - recall: 0.3636\n",
      "Epoch 119/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5028 - acc: 0.5000 - recall: 0.3636\n",
      "Epoch 120/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5028 - acc: 0.5000 - recall: 0.3636\n",
      "Epoch 121/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5027 - acc: 0.5000 - recall: 0.3636\n",
      "Epoch 122/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5027 - acc: 0.5000 - recall: 0.3636\n",
      "Epoch 123/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5026 - acc: 0.5000 - recall: 0.3636\n",
      "Epoch 124/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5026 - acc: 0.5000 - recall: 0.3636\n",
      "Epoch 125/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5026 - acc: 0.5000 - recall: 0.3636\n",
      "Epoch 126/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5026 - acc: 0.5000 - recall: 0.3636\n",
      "Epoch 127/300\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5025 - acc: 0.5000 - recall: 0.3636\n",
      "Epoch 128/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5025 - acc: 0.5000 - recall: 0.3636\n",
      "Epoch 129/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5025 - acc: 0.5000 - recall: 0.3636\n",
      "Epoch 130/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5024 - acc: 0.5000 - recall: 0.3636\n",
      "Epoch 131/300\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5024 - acc: 0.5000 - recall: 0.3636\n",
      "Epoch 132/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5024 - acc: 0.5000 - recall: 0.3636\n",
      "Epoch 133/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5024 - acc: 0.5000 - recall: 0.3636\n",
      "Epoch 134/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5023 - acc: 0.5000 - recall: 0.3636\n",
      "Epoch 135/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5023 - acc: 0.5000 - recall: 0.3636\n",
      "Epoch 136/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5022 - acc: 0.5000 - recall: 0.3636\n",
      "Epoch 137/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5022 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 138/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5022 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 139/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5022 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 140/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5022 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 141/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5021 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 142/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5021 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 143/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5021 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 144/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5021 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 145/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5020 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 146/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5020 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 147/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5020 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 148/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5019 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 149/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5019 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 150/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5018 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 151/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5018 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 152/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5018 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 153/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5018 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 154/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5017 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 155/300\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5017 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 156/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5017 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 157/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5016 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 158/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5016 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 159/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5016 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 160/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5016 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 161/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5015 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 162/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5015 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 163/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5015 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 164/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5014 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 165/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5014 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 166/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5014 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 167/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5013 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 168/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5013 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 169/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5013 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 170/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5013 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 171/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5012 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 172/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5012 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 173/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5012 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 174/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5011 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 175/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5011 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 176/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5011 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 177/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5010 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 178/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5010 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 179/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5010 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 180/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5009 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 181/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5009 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 182/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5009 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 183/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5009 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 184/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5008 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 185/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5008 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 186/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5008 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 187/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5008 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 188/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5007 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 189/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5007 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 190/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5006 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 191/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5006 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 192/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5006 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 193/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5006 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 194/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5006 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 195/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5005 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 196/300\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5005 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 197/300\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5004 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 198/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5004 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 199/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5004 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 200/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5004 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 201/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5003 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 202/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5004 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 203/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5003 - acc: 0.5000 - recall: 0.4091\n",
      "Epoch 204/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5002 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 205/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5002 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 206/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5002 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 207/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5002 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 208/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5001 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 209/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5001 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 210/300\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5001 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 211/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5000 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 212/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5000 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 213/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5000 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 214/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4999 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 215/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4999 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 216/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4999 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 217/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4998 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 218/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4998 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 219/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4998 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 220/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4998 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 221/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4997 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 222/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4997 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 223/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4997 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 224/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4996 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 225/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4996 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 226/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4996 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 227/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4995 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 228/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4995 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 229/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4995 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 230/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4994 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 231/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4994 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 232/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4994 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 233/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4993 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 234/300\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4993 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 235/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4993 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 236/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4993 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 237/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4993 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 238/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4992 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 239/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4992 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 240/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4991 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 241/300\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4991 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 242/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4991 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 243/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4991 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 244/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4991 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 245/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4990 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 246/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4990 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 247/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4989 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 248/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4989 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 249/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4989 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 250/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4988 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 251/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4988 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 252/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4988 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 253/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4987 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 254/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4987 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 255/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4987 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 256/300\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4987 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 257/300\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4986 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 258/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4986 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 259/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4986 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 260/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4985 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 261/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4985 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 262/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4985 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 263/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4985 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 264/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4984 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 265/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4984 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 266/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4983 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 267/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4983 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 268/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4983 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 269/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4983 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 270/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4982 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 271/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4983 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 272/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4982 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 273/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4981 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 274/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4981 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 275/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4981 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 276/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4980 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 277/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4980 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 278/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4980 - acc: 0.5000 - recall: 0.4545\n",
      "Epoch 279/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4980 - acc: 0.5000 - recall: 0.5000\n",
      "Epoch 280/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4979 - acc: 0.5000 - recall: 0.5000\n",
      "Epoch 281/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4979 - acc: 0.5000 - recall: 0.5000\n",
      "Epoch 282/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4979 - acc: 0.5000 - recall: 0.5000\n",
      "Epoch 283/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4978 - acc: 0.5000 - recall: 0.5000\n",
      "Epoch 284/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4978 - acc: 0.5000 - recall: 0.5000\n",
      "Epoch 285/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4978 - acc: 0.5000 - recall: 0.5000\n",
      "Epoch 286/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4978 - acc: 0.5000 - recall: 0.5000\n",
      "Epoch 287/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4978 - acc: 0.5000 - recall: 0.5000\n",
      "Epoch 288/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4977 - acc: 0.5000 - recall: 0.5000\n",
      "Epoch 289/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4977 - acc: 0.5000 - recall: 0.5000\n",
      "Epoch 290/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4976 - acc: 0.5000 - recall: 0.5000\n",
      "Epoch 291/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4976 - acc: 0.5000 - recall: 0.5000\n",
      "Epoch 292/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4976 - acc: 0.5000 - recall: 0.5000\n",
      "Epoch 293/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4975 - acc: 0.5000 - recall: 0.5000\n",
      "Epoch 294/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4975 - acc: 0.5000 - recall: 0.5000\n",
      "Epoch 295/300\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4975 - acc: 0.5000 - recall: 0.5000\n",
      "Epoch 296/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4974 - acc: 0.5000 - recall: 0.5000\n",
      "Epoch 297/300\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4974 - acc: 0.5000 - recall: 0.5000\n",
      "Epoch 298/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4974 - acc: 0.5000 - recall: 0.5000\n",
      "Epoch 299/300\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4973 - acc: 0.5000 - recall: 0.5000\n",
      "Epoch 300/300\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4973 - acc: 0.5000 - recall: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1858c1c99c8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treshold = len(df)\n",
    "\n",
    "x = df[['all','avgall','avg15','1','2','3','4','5']][:treshold].to_numpy()\n",
    "y = []\n",
    "for i in df['answer'][:treshold]:\n",
    "    if i == False:\n",
    "        y.append(1)\n",
    "    elif i == True:\n",
    "        y.append(2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y,stratify=y,test_size=0.5,shuffle=True)\n",
    "\n",
    "X_train = normalize(X_train)\n",
    "X_test = normalize(X_test)\n",
    "\n",
    "# print(y_test,'\\n',y_train)\n",
    "X = tf.convert_to_tensor( X_train,dtype=tf.float64)\n",
    "\n",
    "X = tf.reshape(X,(len(X_train),1,8))\n",
    "\n",
    "Y = []\n",
    "for i in y_train:\n",
    "    if i == 1:\n",
    "        Y.append([1,0])\n",
    "    elif i == 2:\n",
    "        Y.append([0,1])\n",
    "\n",
    "\n",
    "Y = tf.convert_to_tensor(Y)\n",
    "Y = tf.reshape(Y,(len(y_train),1,2))\n",
    "\n",
    "\n",
    "# batch_size = 8\n",
    "# decay_epoch = 20\n",
    "\n",
    "# lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#     initial_learning_rate=0.0001,\n",
    "#     decay_steps=(len(X_train)//batch_size)*decay_epoch,\n",
    "#     decay_rate=0.9)\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer=optimizer, loss='categorical_crossentropy', metrics=[\"acc\"],\n",
    "# )\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_absolute_error',\n",
    "              metrics=['acc','Recall'])\n",
    "\n",
    "model.fit(x = X,y = Y,epochs=300,batch_size=8,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0. 11.]\n",
      " [ 0. 11.]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.convert_to_tensor( X_test,dtype=tf.float64)\n",
    "\n",
    "X = tf.reshape(X,(len(X_test),1,8))\n",
    "\n",
    "m = model.predict(X)\n",
    "\n",
    "res = np.argmax(model.predict(X),axis=-1)\n",
    "\n",
    "mat = np.zeros((2,2))\n",
    "for i in range(len(y_test)):\n",
    "    mat[y_test[i]-1][res[i][0]] += 1\n",
    "\n",
    "print(mat)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  0.208\t0.679\t1.154\n",
    "# s = '''0.5089027420602319,0.8031787381301883,1.0974547342001446,0.9102869789620373,1.1181608841144028,1.1767945775788349,1.1400685436562332,1.141962686689216'''\n",
    "# sample = [float(i) for i in s.split(',') if i]\n",
    "\n",
    "# # line100 = 0.631\n",
    "# # lineall = 0.883\n",
    "# # line5 = 1.137\n",
    "\n",
    "\n",
    "# np.argmax(model(tf.reshape(sample,(1,1,8))))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('envi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7db821986d699a458b6831c207daf06594b2df0f12601a94f5be5a3a8c1e7e9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
